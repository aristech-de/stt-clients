// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.6.1
//   protoc               v5.28.3
// source: stt_service.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import {
  type CallOptions,
  ChannelCredentials,
  Client,
  type ClientDuplexStream,
  type ClientOptions,
  type ClientUnaryCall,
  type handleBidiStreamingCall,
  type handleUnaryCall,
  makeGenericClientConstructor,
  Metadata,
  type ServiceError,
  type UntypedServiceImplementation,
} from "@grpc/grpc-js";
import { Duration } from "./google/protobuf/duration.js";

export const protobufPackage = "ari.stt.v1";

export enum EndpointingType {
  /** LM - Endpointing that considers the language model. */
  LM = 0,
  /** VAD - VAD based endpointing. */
  VAD = 1,
  UNRECOGNIZED = -1,
}

export function endpointingTypeFromJSON(object: any): EndpointingType {
  switch (object) {
    case 0:
    case "LM":
      return EndpointingType.LM;
    case 1:
    case "VAD":
      return EndpointingType.VAD;
    case -1:
    case "UNRECOGNIZED":
    default:
      return EndpointingType.UNRECOGNIZED;
  }
}

export function endpointingTypeToJSON(object: EndpointingType): string {
  switch (object) {
    case EndpointingType.LM:
      return "LM";
    case EndpointingType.VAD:
      return "VAD";
    case EndpointingType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum ModelType {
  /** CORE_STT - STT-Core models */
  CORE_STT = 0,
  /** GRAMMAR_STT - Grammar only models */
  GRAMMAR_STT = 1,
  /** MULTITASK_STT - Multitask models */
  MULTITASK_STT = 2,
  /** DIARIZATION - Speaker diarization model type. */
  DIARIZATION = 3,
  UNRECOGNIZED = -1,
}

export function modelTypeFromJSON(object: any): ModelType {
  switch (object) {
    case 0:
    case "CORE_STT":
      return ModelType.CORE_STT;
    case 1:
    case "GRAMMAR_STT":
      return ModelType.GRAMMAR_STT;
    case 2:
    case "MULTITASK_STT":
      return ModelType.MULTITASK_STT;
    case 3:
    case "DIARIZATION":
      return ModelType.DIARIZATION;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ModelType.UNRECOGNIZED;
  }
}

export function modelTypeToJSON(object: ModelType): string {
  switch (object) {
    case ModelType.CORE_STT:
      return "CORE_STT";
    case ModelType.GRAMMAR_STT:
      return "GRAMMAR_STT";
    case ModelType.MULTITASK_STT:
      return "MULTITASK_STT";
    case ModelType.DIARIZATION:
      return "DIARIZATION";
    case ModelType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum GrammarType {
  /**
   * JSGF - JSGF grammar type.
   * Example grammar: `jsgf:<yes_no> = yes | no;`
   */
  JSGF = 0,
  /**
   * SRGS - SRGS grammar type.
   * Example grammar: `srgs:$yes_no = yes | no;`
   */
  SRGS = 3,
  /**
   * KWS - Keyword / Keyphrase spotting grammar type.
   * Example grammar: `kws:oh mighty computer|hey computer`
   */
  KWS = 1,
  /**
   * PHRASE_LIST - A simple json phrase list grammar type.
   * Example grammar: `["yes", "yeah", "yep", "why not", "no", "nope"]`
   */
  PHRASE_LIST = 2,
  UNRECOGNIZED = -1,
}

export function grammarTypeFromJSON(object: any): GrammarType {
  switch (object) {
    case 0:
    case "JSGF":
      return GrammarType.JSGF;
    case 3:
    case "SRGS":
      return GrammarType.SRGS;
    case 1:
    case "KWS":
      return GrammarType.KWS;
    case 2:
    case "PHRASE_LIST":
      return GrammarType.PHRASE_LIST;
    case -1:
    case "UNRECOGNIZED":
    default:
      return GrammarType.UNRECOGNIZED;
  }
}

export function grammarTypeToJSON(object: GrammarType): string {
  switch (object) {
    case GrammarType.JSGF:
      return "JSGF";
    case GrammarType.SRGS:
      return "SRGS";
    case GrammarType.KWS:
      return "KWS";
    case GrammarType.PHRASE_LIST:
      return "PHRASE_LIST";
    case GrammarType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The top-level message sent by the client for the `StreamingRecognize` method. */
export interface StreamingRecognitionRequest {
  /**
   * The configuration for the stream.
   * This is the first message that must be sent.
   */
  config?:
    | RecognitionConfig
    | undefined;
  /** The audio data to be recognized. */
  audioContent?: Uint8Array | undefined;
}

/** The top-level message returned from the `StreamingRecognize` method. */
export interface StreamingRecognitionResponse {
  /** List of results that are currently available. */
  chunks: SpeechRecognitionChunk[];
  /**
   * A short id that is used in the stt-server logs to differentiate between
   * different client requests. Be aware that this id should only be used for
   * debugging purposes because it is not collision safe.
   */
  clientId: string;
  /** The language identified by the server, e.g. en, de, etc. */
  language: string;
}

/**
 * The `RecognitionConfig` message provides information to the recognizer that
 * specifies how to process the request.
 */
export interface RecognitionConfig {
  /**
   * Specifies what kind of audio is being sent and how the recognizer should
   * process it.
   */
  specification: RecognitionSpec | undefined;
}

/**
 * The `RecognitionSpec` message provides information to the recognizer that
 * specifies how to process the request.
 */
export interface RecognitionSpec {
  /** At the moment only LINEAR16 is supported. */
  audioEncoding: RecognitionSpec_AudioEncoding;
  /** 8000, 16000, 48000 only for pcm. */
  sampleRateHertz: number;
  /** [language[_territory]] e.g. en, en-IN, de. */
  locale: string;
  /** load a specific graph for the locale specific model (e.g. yes_no). */
  graph: string;
  /**
   * Allows to specify a grammar to be used for the recognition.
   * To specify a JSGF grammar for example set grammar to `jsgf:public <yes_no>
   * = yes | no;` To spot a keyword / phrase, set grammar to `kws:oh mighty
   * computer` You can also specify a json string to narrow the possible words
   * to appear `["oh one two three four five six seven eight nine zero",
   * "[unk]"]`.
   */
  grammar: string;
  /**
   * If set true, tentative hypotheses may be returned as they become available
   * (final=false flag) If false or omitted, only final=true result(s) are
   * returned. Makes sense only for StreamingRecognize requests.
   */
  partialResults: boolean;
  /** Decode as single utterance. */
  singleUtterance: boolean;
  /** Specifies how text should be normalized. */
  normalization:
    | NormalizationSpec
    | undefined;
  /**
   * When set, the recognizer opts out of MBR decoding and produces phoneme
   * infos.
   */
  phones: boolean;
  /**
   * Instead of picking a model based on the locale, this field can be used to
   * specify a specific model directly.
   * To specify a graph model directly use model:graph e.g.
   * generic-model-de-0.21:ja_nein
   */
  model: string;
  /**
   * For models that use endpointing (e.g. STT-Core models) this field can be
   * used to specify the endpointing configuration.
   */
  endpointing:
    | EndpointSpec
    | undefined;
  /**
   * For models that use voice activity detection (VAD) this field can be used
   * to specify the VAD configuration.
   */
  vad:
    | VadSpec
    | undefined;
  /**
   * Some models allow to specify a prompt that can be used to give the model
   * some context on what was said before or to steer the model to use
   * particular spellings or styles.
   */
  prompt: string;
}

export enum RecognitionSpec_AudioEncoding {
  /** AUDIO_ENCODING_UNSPECIFIED - If not specified, defaults to LINEAR16_PCM. */
  AUDIO_ENCODING_UNSPECIFIED = 0,
  /** LINEAR16_PCM - 16-bit signed little-endian (Linear PCM) */
  LINEAR16_PCM = 1,
  UNRECOGNIZED = -1,
}

export function recognitionSpec_AudioEncodingFromJSON(object: any): RecognitionSpec_AudioEncoding {
  switch (object) {
    case 0:
    case "AUDIO_ENCODING_UNSPECIFIED":
      return RecognitionSpec_AudioEncoding.AUDIO_ENCODING_UNSPECIFIED;
    case 1:
    case "LINEAR16_PCM":
      return RecognitionSpec_AudioEncoding.LINEAR16_PCM;
    case -1:
    case "UNRECOGNIZED":
    default:
      return RecognitionSpec_AudioEncoding.UNRECOGNIZED;
  }
}

export function recognitionSpec_AudioEncodingToJSON(object: RecognitionSpec_AudioEncoding): string {
  switch (object) {
    case RecognitionSpec_AudioEncoding.AUDIO_ENCODING_UNSPECIFIED:
      return "AUDIO_ENCODING_UNSPECIFIED";
    case RecognitionSpec_AudioEncoding.LINEAR16_PCM:
      return "LINEAR16_PCM";
    case RecognitionSpec_AudioEncoding.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * The `NormalizationSpec` message provides information to the recognizer that
 * specifies which normalizer to use.
 */
export interface NormalizationSpec {
  /**
   * Whether to strip unknown label in the resulting text
   * Note: The unknown label can still be accessed via the `words` field
   */
  stripUnk: boolean;
  /**
   * Allows to specify which nlp functions should be applied to the text
   * before it is returned. By specifying this field, the default nlp
   * configuration is overwritten.
   */
  nlp: NLPSpec | undefined;
}

export interface NLPSpec {
  /** The server config name of the server that provides the nlp functions. */
  serverConfig: string;
  /** Which nlp functions should be applied to the text before it is returned. */
  functions: NLPFunctionSpec[];
  /** Whether to apply the nlp functions to the partial results. */
  partialResults: boolean;
  /** Optional global argument. */
  args: string;
  /** Specifies which field should be used as input for the nlp functions. */
  inputField: NLPSpec_NlpInputField;
}

export enum NLPSpec_NlpInputField {
  /** UNSPECIFIED - If not specified, defaults to TEXT. */
  UNSPECIFIED = 0,
  /** TEXT - The text field is used as input for the nlp processing. */
  TEXT = 1,
  /** TAGGED_TEXT - Use the tagged_text field as input for the nlp processing. */
  TAGGED_TEXT = 2,
  /** SLOTTED_TEXT - Use the slotted_text field as input for the nlp processing. */
  SLOTTED_TEXT = 3,
  UNRECOGNIZED = -1,
}

export function nLPSpec_NlpInputFieldFromJSON(object: any): NLPSpec_NlpInputField {
  switch (object) {
    case 0:
    case "UNSPECIFIED":
      return NLPSpec_NlpInputField.UNSPECIFIED;
    case 1:
    case "TEXT":
      return NLPSpec_NlpInputField.TEXT;
    case 2:
    case "TAGGED_TEXT":
      return NLPSpec_NlpInputField.TAGGED_TEXT;
    case 3:
    case "SLOTTED_TEXT":
      return NLPSpec_NlpInputField.SLOTTED_TEXT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return NLPSpec_NlpInputField.UNRECOGNIZED;
  }
}

export function nLPSpec_NlpInputFieldToJSON(object: NLPSpec_NlpInputField): string {
  switch (object) {
    case NLPSpec_NlpInputField.UNSPECIFIED:
      return "UNSPECIFIED";
    case NLPSpec_NlpInputField.TEXT:
      return "TEXT";
    case NLPSpec_NlpInputField.TAGGED_TEXT:
      return "TAGGED_TEXT";
    case NLPSpec_NlpInputField.SLOTTED_TEXT:
      return "SLOTTED_TEXT";
    case NLPSpec_NlpInputField.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * The `NLPFunction` message provides information to the recognizer that
 * specifies which nlp function to use.
 */
export interface NLPFunctionSpec {
  /** The id of the nlp function (e.g. `ner-de`). */
  id: string;
  /** Optional additional parameters for the nlp function (e.g. `ANONYMIZE`). */
  args: string[];
}

/** Endpointing configuration for LM based endpointing. */
export interface EndpointSpec {
  /**
   * How many seconds of non-speech before the endpointer triggers to
   * clean up the buffer.
   */
  silenceTimeout: number;
  /**
   * How many seconds of non-speech after some speech with high
   * probability for an endpoint before the endpointer triggers.
   */
  trailingSilenceHighProbability: number;
  /**
   * How many seconds of non-speech after some speech with low probability
   * for an endpoint before the endpointer triggers.
   */
  trailingSilenceOkProbability: number;
  /**
   * How many seconds of non-speech without the endpointer reaching a
   * final state before the endpointer triggers.
   */
  trailingSilenceNoEndpoint: number;
  /**
   * After how many seconds of audio to trigger and endpoint regardless
   * of anything else.
   */
  utteranceTimeout: number;
}

/**
 * Endpointing configuration for Voice activity detection (VAD) based
 * endpointing.
 */
export interface VadSpec {
  /**
   * The threshold between 0 and 1.0 to determine if a frame is speech or
   * non-speech. A higher threshold will result in less false positives but also
   * some speech might be cut off.
   */
  threshold: number;
  /**
   * Amount of trailing silence before an utterance is considered after a speech
   * to non-speech transition.
   */
  trailingSilence: number;
  /**
   * The minimum duration of speech in seconds before trying to perform a
   * partial recognition.
   */
  minSpeech: number;
}

/**
 * The `SpeechRecognitionChunk` message contains the result of a single
 * utterance.
 */
export interface SpeechRecognitionChunk {
  /** The transcription alternatives. */
  alternatives: SpeechRecognitionAlternative[];
  /** This flag indicates if the transcription is final or not. */
  final: boolean;
  /** This flag shows that the received chunk is the end of an utterance. */
  endOfUtterance: boolean;
}

/**
 * The `SpeechRecognitionAlternative` message contains one alternative of a
 * transcription.
 */
export interface SpeechRecognitionAlternative {
  /** The raw recognized text. */
  text: string;
  /**
   * When the model is composed of multiple nested language models, this field
   * contains the recognized text including xml tags that indicate which
   * language model produced which part of the text. e.g. "i live in <address>
   * <number> 21 </number> <street> jumpstreet </street> <city> heidelberg
   * </city> </address>"
   */
  slottedText: string;
  /** The tagged recognized text. */
  taggedText: string;
  /** The nlp result. */
  nlpText: string;
  /** The overall confidence of the recognition result. */
  confidence: number;
  /**
   * Word level infos such as start and end time offsets, word level
   * confidences, or phoneme infos.
   */
  words: WordInfo[];
}

/** The `WordInfo` message contains the word level information. */
export interface WordInfo {
  /** The word's start time, in seconds. */
  startTime:
    | Duration
    | undefined;
  /** The word's end time, in seconds. */
  endTime:
    | Duration
    | undefined;
  /** The word. */
  word: string;
  /** The confidence of the word in the range [0.0, 1.0]. */
  confidence: number;
  /** Phoneme infos. */
  phones: PhoneInfo[];
  /**
   * Speech recognition slot the word belongs to.
   * For nested slots, the slots are joined with a dot and ordered from outer to
   * inner
   * e.g.: "i live in <address> <number> 21 </number> <street> jumpstreet
   * </street> heidelberg </address>"
   * will have the following slots:
   * i -> ''
   * live -> ''
   * in -> ''
   * 21 -> 'address.number'
   * jumpstreet -> 'address.street'
   * heidelberg -> 'address'
   */
  slot: string;
}

/** The `PhoneInfo` message contains the phoneme level information. */
export interface PhoneInfo {
  /** The phone's start time, in seconds. */
  startTime:
    | Duration
    | undefined;
  /** The phone's end time, in seconds. */
  endTime:
    | Duration
    | undefined;
  /** The phone. */
  phone: string;
}

/** The `ModelsRequest` message currently contains no information. */
export interface ModelsRequest {
}

/** The `ModelsResponse` message contains the list of supported models. */
export interface ModelsResponse {
  /** List of supported models. */
  model: Model[];
}

/** The `Model` message contains the information about a single model. */
export interface Model {
  /**
   * The model id.
   * e.g. generic-model-de-0.21
   */
  id: string;
  /**
   * Alias that can also be used to refer to the model instead of the id.
   * e.g. generic-de or german-large
   */
  alias: string[];
  /**
   * The human readable model name (for display purposes).
   * e.g. German Generic Model (Large)
   */
  name: string;
  /** The model description. */
  description: string;
  /** The model version. */
  version: string;
  /** The model type. */
  type: ModelType;
  /** The locale(s) supported by the model. */
  locale: string[];
  /** Which grammar types are supported by the model. */
  grammarType: GrammarType[];
  /** The NLP preconfiguration for this model (if any). */
  nlp:
    | NLPSpec
    | undefined;
  /** The slots the model potentially outputs. */
  slots: string[];
  /** Examples of what the model can recognize. */
  examples: string[];
  /** The supported endpointing modes. */
  endpointing: EndpointingType[];
}

/** The `NLPFunctionsRequest` message currently contains no information. */
export interface NLPFunctionsRequest {
}

/**
 * The `NLPFunctionsResponse` message contains the list of supported nlp
 * servers and the corresponding functions.
 */
export interface NLPFunctionsResponse {
  /** List of supported nlp servers. */
  server: NLPFunctionServer[];
}

export interface NLPFunctionServer {
  /** The nlp server configuration name (to be used in `NLPSpec`). */
  serverConfig: string;
  /** The nlp functions supported by the nlp server. */
  functions: NLPFunction[];
}

/**
 * The `NLPFunction` message contains the information about a single nlp
 * function.
 */
export interface NLPFunction {
  /** The nlp function id. */
  id: string;
  /** The nlp function name. */
  name: string;
  /** The nlp function description. */
  description: string;
}

/** The `Graph` message contains the information about a single graph. */
export interface Graph {
  /** The name of the graph */
  name: string;
}

/** The `AccountInfoRequest` message currently contains no information. */
export interface AccountInfoRequest {
}

/** The `AccountInfoResponse` message contains the account information. */
export interface AccountInfoResponse {
  /** The account token. */
  token: string;
  /** The account display name. */
  displayName: string;
  /** How many requests were made with this account. */
  totalRequests: number;
  /** How many seconds of audio this account has booked. */
  bookedSeconds: number;
  /** How many seconds of audio this account has used. */
  usedSeconds: number;
  /** Expiration date of the account as unix timestamp (-1 for unlimited). */
  expirationDate: number;
  /** Whether the account is blocked. */
  blocked: boolean;
}

/** The `NLPProcessRequest` message contains the text to be processed. */
export interface NLPProcessRequest {
  /** The text to be processed. */
  text: string;
  /** The nlp specification. */
  nlp: NLPSpec | undefined;
}

/** The `NLPProcessResponse` message contains the processed text. */
export interface NLPProcessResponse {
  /** The processed text. */
  text: string;
}

function createBaseStreamingRecognitionRequest(): StreamingRecognitionRequest {
  return { config: undefined, audioContent: undefined };
}

export const StreamingRecognitionRequest: MessageFns<StreamingRecognitionRequest> = {
  encode(message: StreamingRecognitionRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.config !== undefined) {
      RecognitionConfig.encode(message.config, writer.uint32(10).fork()).join();
    }
    if (message.audioContent !== undefined) {
      writer.uint32(18).bytes(message.audioContent);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingRecognitionRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingRecognitionRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.config = RecognitionConfig.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.audioContent = reader.bytes();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingRecognitionRequest {
    return {
      config: isSet(object.config) ? RecognitionConfig.fromJSON(object.config) : undefined,
      audioContent: isSet(object.audioContent) ? bytesFromBase64(object.audioContent) : undefined,
    };
  },

  toJSON(message: StreamingRecognitionRequest): unknown {
    const obj: any = {};
    if (message.config !== undefined) {
      obj.config = RecognitionConfig.toJSON(message.config);
    }
    if (message.audioContent !== undefined) {
      obj.audioContent = base64FromBytes(message.audioContent);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<StreamingRecognitionRequest>, I>>(base?: I): StreamingRecognitionRequest {
    return StreamingRecognitionRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<StreamingRecognitionRequest>, I>>(object: I): StreamingRecognitionRequest {
    const message = createBaseStreamingRecognitionRequest();
    message.config = (object.config !== undefined && object.config !== null)
      ? RecognitionConfig.fromPartial(object.config)
      : undefined;
    message.audioContent = object.audioContent ?? undefined;
    return message;
  },
};

function createBaseStreamingRecognitionResponse(): StreamingRecognitionResponse {
  return { chunks: [], clientId: "", language: "" };
}

export const StreamingRecognitionResponse: MessageFns<StreamingRecognitionResponse> = {
  encode(message: StreamingRecognitionResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.chunks) {
      SpeechRecognitionChunk.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.clientId !== "") {
      writer.uint32(26).string(message.clientId);
    }
    if (message.language !== "") {
      writer.uint32(34).string(message.language);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StreamingRecognitionResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStreamingRecognitionResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.chunks.push(SpeechRecognitionChunk.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.clientId = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.language = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StreamingRecognitionResponse {
    return {
      chunks: globalThis.Array.isArray(object?.chunks)
        ? object.chunks.map((e: any) => SpeechRecognitionChunk.fromJSON(e))
        : [],
      clientId: isSet(object.clientId) ? globalThis.String(object.clientId) : "",
      language: isSet(object.language) ? globalThis.String(object.language) : "",
    };
  },

  toJSON(message: StreamingRecognitionResponse): unknown {
    const obj: any = {};
    if (message.chunks?.length) {
      obj.chunks = message.chunks.map((e) => SpeechRecognitionChunk.toJSON(e));
    }
    if (message.clientId !== "") {
      obj.clientId = message.clientId;
    }
    if (message.language !== "") {
      obj.language = message.language;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<StreamingRecognitionResponse>, I>>(base?: I): StreamingRecognitionResponse {
    return StreamingRecognitionResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<StreamingRecognitionResponse>, I>>(object: I): StreamingRecognitionResponse {
    const message = createBaseStreamingRecognitionResponse();
    message.chunks = object.chunks?.map((e) => SpeechRecognitionChunk.fromPartial(e)) || [];
    message.clientId = object.clientId ?? "";
    message.language = object.language ?? "";
    return message;
  },
};

function createBaseRecognitionConfig(): RecognitionConfig {
  return { specification: undefined };
}

export const RecognitionConfig: MessageFns<RecognitionConfig> = {
  encode(message: RecognitionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.specification !== undefined) {
      RecognitionSpec.encode(message.specification, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RecognitionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecognitionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.specification = RecognitionSpec.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RecognitionConfig {
    return { specification: isSet(object.specification) ? RecognitionSpec.fromJSON(object.specification) : undefined };
  },

  toJSON(message: RecognitionConfig): unknown {
    const obj: any = {};
    if (message.specification !== undefined) {
      obj.specification = RecognitionSpec.toJSON(message.specification);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RecognitionConfig>, I>>(base?: I): RecognitionConfig {
    return RecognitionConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RecognitionConfig>, I>>(object: I): RecognitionConfig {
    const message = createBaseRecognitionConfig();
    message.specification = (object.specification !== undefined && object.specification !== null)
      ? RecognitionSpec.fromPartial(object.specification)
      : undefined;
    return message;
  },
};

function createBaseRecognitionSpec(): RecognitionSpec {
  return {
    audioEncoding: 0,
    sampleRateHertz: 0,
    locale: "",
    graph: "",
    grammar: "",
    partialResults: false,
    singleUtterance: false,
    normalization: undefined,
    phones: false,
    model: "",
    endpointing: undefined,
    vad: undefined,
    prompt: "",
  };
}

export const RecognitionSpec: MessageFns<RecognitionSpec> = {
  encode(message: RecognitionSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.audioEncoding !== 0) {
      writer.uint32(8).int32(message.audioEncoding);
    }
    if (message.sampleRateHertz !== 0) {
      writer.uint32(16).int64(message.sampleRateHertz);
    }
    if (message.locale !== "") {
      writer.uint32(26).string(message.locale);
    }
    if (message.graph !== "") {
      writer.uint32(42).string(message.graph);
    }
    if (message.grammar !== "") {
      writer.uint32(50).string(message.grammar);
    }
    if (message.partialResults !== false) {
      writer.uint32(56).bool(message.partialResults);
    }
    if (message.singleUtterance !== false) {
      writer.uint32(64).bool(message.singleUtterance);
    }
    if (message.normalization !== undefined) {
      NormalizationSpec.encode(message.normalization, writer.uint32(74).fork()).join();
    }
    if (message.phones !== false) {
      writer.uint32(80).bool(message.phones);
    }
    if (message.model !== "") {
      writer.uint32(90).string(message.model);
    }
    if (message.endpointing !== undefined) {
      EndpointSpec.encode(message.endpointing, writer.uint32(98).fork()).join();
    }
    if (message.vad !== undefined) {
      VadSpec.encode(message.vad, writer.uint32(106).fork()).join();
    }
    if (message.prompt !== "") {
      writer.uint32(114).string(message.prompt);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RecognitionSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRecognitionSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.audioEncoding = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.sampleRateHertz = longToNumber(reader.int64());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.locale = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.graph = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.grammar = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.partialResults = reader.bool();
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.singleUtterance = reader.bool();
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.normalization = NormalizationSpec.decode(reader, reader.uint32());
          continue;
        }
        case 10: {
          if (tag !== 80) {
            break;
          }

          message.phones = reader.bool();
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.model = reader.string();
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.endpointing = EndpointSpec.decode(reader, reader.uint32());
          continue;
        }
        case 13: {
          if (tag !== 106) {
            break;
          }

          message.vad = VadSpec.decode(reader, reader.uint32());
          continue;
        }
        case 14: {
          if (tag !== 114) {
            break;
          }

          message.prompt = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RecognitionSpec {
    return {
      audioEncoding: isSet(object.audioEncoding) ? recognitionSpec_AudioEncodingFromJSON(object.audioEncoding) : 0,
      sampleRateHertz: isSet(object.sampleRateHertz) ? globalThis.Number(object.sampleRateHertz) : 0,
      locale: isSet(object.locale) ? globalThis.String(object.locale) : "",
      graph: isSet(object.graph) ? globalThis.String(object.graph) : "",
      grammar: isSet(object.grammar) ? globalThis.String(object.grammar) : "",
      partialResults: isSet(object.partialResults) ? globalThis.Boolean(object.partialResults) : false,
      singleUtterance: isSet(object.singleUtterance) ? globalThis.Boolean(object.singleUtterance) : false,
      normalization: isSet(object.normalization) ? NormalizationSpec.fromJSON(object.normalization) : undefined,
      phones: isSet(object.phones) ? globalThis.Boolean(object.phones) : false,
      model: isSet(object.model) ? globalThis.String(object.model) : "",
      endpointing: isSet(object.endpointing) ? EndpointSpec.fromJSON(object.endpointing) : undefined,
      vad: isSet(object.vad) ? VadSpec.fromJSON(object.vad) : undefined,
      prompt: isSet(object.prompt) ? globalThis.String(object.prompt) : "",
    };
  },

  toJSON(message: RecognitionSpec): unknown {
    const obj: any = {};
    if (message.audioEncoding !== 0) {
      obj.audioEncoding = recognitionSpec_AudioEncodingToJSON(message.audioEncoding);
    }
    if (message.sampleRateHertz !== 0) {
      obj.sampleRateHertz = Math.round(message.sampleRateHertz);
    }
    if (message.locale !== "") {
      obj.locale = message.locale;
    }
    if (message.graph !== "") {
      obj.graph = message.graph;
    }
    if (message.grammar !== "") {
      obj.grammar = message.grammar;
    }
    if (message.partialResults !== false) {
      obj.partialResults = message.partialResults;
    }
    if (message.singleUtterance !== false) {
      obj.singleUtterance = message.singleUtterance;
    }
    if (message.normalization !== undefined) {
      obj.normalization = NormalizationSpec.toJSON(message.normalization);
    }
    if (message.phones !== false) {
      obj.phones = message.phones;
    }
    if (message.model !== "") {
      obj.model = message.model;
    }
    if (message.endpointing !== undefined) {
      obj.endpointing = EndpointSpec.toJSON(message.endpointing);
    }
    if (message.vad !== undefined) {
      obj.vad = VadSpec.toJSON(message.vad);
    }
    if (message.prompt !== "") {
      obj.prompt = message.prompt;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RecognitionSpec>, I>>(base?: I): RecognitionSpec {
    return RecognitionSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RecognitionSpec>, I>>(object: I): RecognitionSpec {
    const message = createBaseRecognitionSpec();
    message.audioEncoding = object.audioEncoding ?? 0;
    message.sampleRateHertz = object.sampleRateHertz ?? 0;
    message.locale = object.locale ?? "";
    message.graph = object.graph ?? "";
    message.grammar = object.grammar ?? "";
    message.partialResults = object.partialResults ?? false;
    message.singleUtterance = object.singleUtterance ?? false;
    message.normalization = (object.normalization !== undefined && object.normalization !== null)
      ? NormalizationSpec.fromPartial(object.normalization)
      : undefined;
    message.phones = object.phones ?? false;
    message.model = object.model ?? "";
    message.endpointing = (object.endpointing !== undefined && object.endpointing !== null)
      ? EndpointSpec.fromPartial(object.endpointing)
      : undefined;
    message.vad = (object.vad !== undefined && object.vad !== null) ? VadSpec.fromPartial(object.vad) : undefined;
    message.prompt = object.prompt ?? "";
    return message;
  },
};

function createBaseNormalizationSpec(): NormalizationSpec {
  return { stripUnk: false, nlp: undefined };
}

export const NormalizationSpec: MessageFns<NormalizationSpec> = {
  encode(message: NormalizationSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.stripUnk !== false) {
      writer.uint32(16).bool(message.stripUnk);
    }
    if (message.nlp !== undefined) {
      NLPSpec.encode(message.nlp, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NormalizationSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNormalizationSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.stripUnk = reader.bool();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.nlp = NLPSpec.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NormalizationSpec {
    return {
      stripUnk: isSet(object.stripUnk) ? globalThis.Boolean(object.stripUnk) : false,
      nlp: isSet(object.nlp) ? NLPSpec.fromJSON(object.nlp) : undefined,
    };
  },

  toJSON(message: NormalizationSpec): unknown {
    const obj: any = {};
    if (message.stripUnk !== false) {
      obj.stripUnk = message.stripUnk;
    }
    if (message.nlp !== undefined) {
      obj.nlp = NLPSpec.toJSON(message.nlp);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NormalizationSpec>, I>>(base?: I): NormalizationSpec {
    return NormalizationSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NormalizationSpec>, I>>(object: I): NormalizationSpec {
    const message = createBaseNormalizationSpec();
    message.stripUnk = object.stripUnk ?? false;
    message.nlp = (object.nlp !== undefined && object.nlp !== null) ? NLPSpec.fromPartial(object.nlp) : undefined;
    return message;
  },
};

function createBaseNLPSpec(): NLPSpec {
  return { serverConfig: "", functions: [], partialResults: false, args: "", inputField: 0 };
}

export const NLPSpec: MessageFns<NLPSpec> = {
  encode(message: NLPSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.serverConfig !== "") {
      writer.uint32(10).string(message.serverConfig);
    }
    for (const v of message.functions) {
      NLPFunctionSpec.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.partialResults !== false) {
      writer.uint32(24).bool(message.partialResults);
    }
    if (message.args !== "") {
      writer.uint32(34).string(message.args);
    }
    if (message.inputField !== 0) {
      writer.uint32(40).int32(message.inputField);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NLPSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNLPSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.serverConfig = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.functions.push(NLPFunctionSpec.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.partialResults = reader.bool();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.args = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.inputField = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NLPSpec {
    return {
      serverConfig: isSet(object.serverConfig) ? globalThis.String(object.serverConfig) : "",
      functions: globalThis.Array.isArray(object?.functions)
        ? object.functions.map((e: any) => NLPFunctionSpec.fromJSON(e))
        : [],
      partialResults: isSet(object.partialResults) ? globalThis.Boolean(object.partialResults) : false,
      args: isSet(object.args) ? globalThis.String(object.args) : "",
      inputField: isSet(object.inputField) ? nLPSpec_NlpInputFieldFromJSON(object.inputField) : 0,
    };
  },

  toJSON(message: NLPSpec): unknown {
    const obj: any = {};
    if (message.serverConfig !== "") {
      obj.serverConfig = message.serverConfig;
    }
    if (message.functions?.length) {
      obj.functions = message.functions.map((e) => NLPFunctionSpec.toJSON(e));
    }
    if (message.partialResults !== false) {
      obj.partialResults = message.partialResults;
    }
    if (message.args !== "") {
      obj.args = message.args;
    }
    if (message.inputField !== 0) {
      obj.inputField = nLPSpec_NlpInputFieldToJSON(message.inputField);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NLPSpec>, I>>(base?: I): NLPSpec {
    return NLPSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NLPSpec>, I>>(object: I): NLPSpec {
    const message = createBaseNLPSpec();
    message.serverConfig = object.serverConfig ?? "";
    message.functions = object.functions?.map((e) => NLPFunctionSpec.fromPartial(e)) || [];
    message.partialResults = object.partialResults ?? false;
    message.args = object.args ?? "";
    message.inputField = object.inputField ?? 0;
    return message;
  },
};

function createBaseNLPFunctionSpec(): NLPFunctionSpec {
  return { id: "", args: [] };
}

export const NLPFunctionSpec: MessageFns<NLPFunctionSpec> = {
  encode(message: NLPFunctionSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    for (const v of message.args) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NLPFunctionSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNLPFunctionSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.args.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NLPFunctionSpec {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      args: globalThis.Array.isArray(object?.args) ? object.args.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: NLPFunctionSpec): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.args?.length) {
      obj.args = message.args;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NLPFunctionSpec>, I>>(base?: I): NLPFunctionSpec {
    return NLPFunctionSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NLPFunctionSpec>, I>>(object: I): NLPFunctionSpec {
    const message = createBaseNLPFunctionSpec();
    message.id = object.id ?? "";
    message.args = object.args?.map((e) => e) || [];
    return message;
  },
};

function createBaseEndpointSpec(): EndpointSpec {
  return {
    silenceTimeout: 0,
    trailingSilenceHighProbability: 0,
    trailingSilenceOkProbability: 0,
    trailingSilenceNoEndpoint: 0,
    utteranceTimeout: 0,
  };
}

export const EndpointSpec: MessageFns<EndpointSpec> = {
  encode(message: EndpointSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.silenceTimeout !== 0) {
      writer.uint32(13).float(message.silenceTimeout);
    }
    if (message.trailingSilenceHighProbability !== 0) {
      writer.uint32(21).float(message.trailingSilenceHighProbability);
    }
    if (message.trailingSilenceOkProbability !== 0) {
      writer.uint32(29).float(message.trailingSilenceOkProbability);
    }
    if (message.trailingSilenceNoEndpoint !== 0) {
      writer.uint32(37).float(message.trailingSilenceNoEndpoint);
    }
    if (message.utteranceTimeout !== 0) {
      writer.uint32(45).float(message.utteranceTimeout);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EndpointSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEndpointSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 13) {
            break;
          }

          message.silenceTimeout = reader.float();
          continue;
        }
        case 2: {
          if (tag !== 21) {
            break;
          }

          message.trailingSilenceHighProbability = reader.float();
          continue;
        }
        case 3: {
          if (tag !== 29) {
            break;
          }

          message.trailingSilenceOkProbability = reader.float();
          continue;
        }
        case 4: {
          if (tag !== 37) {
            break;
          }

          message.trailingSilenceNoEndpoint = reader.float();
          continue;
        }
        case 5: {
          if (tag !== 45) {
            break;
          }

          message.utteranceTimeout = reader.float();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EndpointSpec {
    return {
      silenceTimeout: isSet(object.silenceTimeout) ? globalThis.Number(object.silenceTimeout) : 0,
      trailingSilenceHighProbability: isSet(object.trailingSilenceHighProbability)
        ? globalThis.Number(object.trailingSilenceHighProbability)
        : 0,
      trailingSilenceOkProbability: isSet(object.trailingSilenceOkProbability)
        ? globalThis.Number(object.trailingSilenceOkProbability)
        : 0,
      trailingSilenceNoEndpoint: isSet(object.trailingSilenceNoEndpoint)
        ? globalThis.Number(object.trailingSilenceNoEndpoint)
        : 0,
      utteranceTimeout: isSet(object.utteranceTimeout) ? globalThis.Number(object.utteranceTimeout) : 0,
    };
  },

  toJSON(message: EndpointSpec): unknown {
    const obj: any = {};
    if (message.silenceTimeout !== 0) {
      obj.silenceTimeout = message.silenceTimeout;
    }
    if (message.trailingSilenceHighProbability !== 0) {
      obj.trailingSilenceHighProbability = message.trailingSilenceHighProbability;
    }
    if (message.trailingSilenceOkProbability !== 0) {
      obj.trailingSilenceOkProbability = message.trailingSilenceOkProbability;
    }
    if (message.trailingSilenceNoEndpoint !== 0) {
      obj.trailingSilenceNoEndpoint = message.trailingSilenceNoEndpoint;
    }
    if (message.utteranceTimeout !== 0) {
      obj.utteranceTimeout = message.utteranceTimeout;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<EndpointSpec>, I>>(base?: I): EndpointSpec {
    return EndpointSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<EndpointSpec>, I>>(object: I): EndpointSpec {
    const message = createBaseEndpointSpec();
    message.silenceTimeout = object.silenceTimeout ?? 0;
    message.trailingSilenceHighProbability = object.trailingSilenceHighProbability ?? 0;
    message.trailingSilenceOkProbability = object.trailingSilenceOkProbability ?? 0;
    message.trailingSilenceNoEndpoint = object.trailingSilenceNoEndpoint ?? 0;
    message.utteranceTimeout = object.utteranceTimeout ?? 0;
    return message;
  },
};

function createBaseVadSpec(): VadSpec {
  return { threshold: 0, trailingSilence: 0, minSpeech: 0 };
}

export const VadSpec: MessageFns<VadSpec> = {
  encode(message: VadSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.threshold !== 0) {
      writer.uint32(13).float(message.threshold);
    }
    if (message.trailingSilence !== 0) {
      writer.uint32(21).float(message.trailingSilence);
    }
    if (message.minSpeech !== 0) {
      writer.uint32(29).float(message.minSpeech);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VadSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVadSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 13) {
            break;
          }

          message.threshold = reader.float();
          continue;
        }
        case 2: {
          if (tag !== 21) {
            break;
          }

          message.trailingSilence = reader.float();
          continue;
        }
        case 3: {
          if (tag !== 29) {
            break;
          }

          message.minSpeech = reader.float();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VadSpec {
    return {
      threshold: isSet(object.threshold) ? globalThis.Number(object.threshold) : 0,
      trailingSilence: isSet(object.trailingSilence) ? globalThis.Number(object.trailingSilence) : 0,
      minSpeech: isSet(object.minSpeech) ? globalThis.Number(object.minSpeech) : 0,
    };
  },

  toJSON(message: VadSpec): unknown {
    const obj: any = {};
    if (message.threshold !== 0) {
      obj.threshold = message.threshold;
    }
    if (message.trailingSilence !== 0) {
      obj.trailingSilence = message.trailingSilence;
    }
    if (message.minSpeech !== 0) {
      obj.minSpeech = message.minSpeech;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<VadSpec>, I>>(base?: I): VadSpec {
    return VadSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<VadSpec>, I>>(object: I): VadSpec {
    const message = createBaseVadSpec();
    message.threshold = object.threshold ?? 0;
    message.trailingSilence = object.trailingSilence ?? 0;
    message.minSpeech = object.minSpeech ?? 0;
    return message;
  },
};

function createBaseSpeechRecognitionChunk(): SpeechRecognitionChunk {
  return { alternatives: [], final: false, endOfUtterance: false };
}

export const SpeechRecognitionChunk: MessageFns<SpeechRecognitionChunk> = {
  encode(message: SpeechRecognitionChunk, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.alternatives) {
      SpeechRecognitionAlternative.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.final !== false) {
      writer.uint32(16).bool(message.final);
    }
    if (message.endOfUtterance !== false) {
      writer.uint32(24).bool(message.endOfUtterance);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SpeechRecognitionChunk {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSpeechRecognitionChunk();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.alternatives.push(SpeechRecognitionAlternative.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.final = reader.bool();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.endOfUtterance = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SpeechRecognitionChunk {
    return {
      alternatives: globalThis.Array.isArray(object?.alternatives)
        ? object.alternatives.map((e: any) => SpeechRecognitionAlternative.fromJSON(e))
        : [],
      final: isSet(object.final) ? globalThis.Boolean(object.final) : false,
      endOfUtterance: isSet(object.endOfUtterance) ? globalThis.Boolean(object.endOfUtterance) : false,
    };
  },

  toJSON(message: SpeechRecognitionChunk): unknown {
    const obj: any = {};
    if (message.alternatives?.length) {
      obj.alternatives = message.alternatives.map((e) => SpeechRecognitionAlternative.toJSON(e));
    }
    if (message.final !== false) {
      obj.final = message.final;
    }
    if (message.endOfUtterance !== false) {
      obj.endOfUtterance = message.endOfUtterance;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SpeechRecognitionChunk>, I>>(base?: I): SpeechRecognitionChunk {
    return SpeechRecognitionChunk.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SpeechRecognitionChunk>, I>>(object: I): SpeechRecognitionChunk {
    const message = createBaseSpeechRecognitionChunk();
    message.alternatives = object.alternatives?.map((e) => SpeechRecognitionAlternative.fromPartial(e)) || [];
    message.final = object.final ?? false;
    message.endOfUtterance = object.endOfUtterance ?? false;
    return message;
  },
};

function createBaseSpeechRecognitionAlternative(): SpeechRecognitionAlternative {
  return { text: "", slottedText: "", taggedText: "", nlpText: "", confidence: 0, words: [] };
}

export const SpeechRecognitionAlternative: MessageFns<SpeechRecognitionAlternative> = {
  encode(message: SpeechRecognitionAlternative, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.text !== "") {
      writer.uint32(10).string(message.text);
    }
    if (message.slottedText !== "") {
      writer.uint32(58).string(message.slottedText);
    }
    if (message.taggedText !== "") {
      writer.uint32(42).string(message.taggedText);
    }
    if (message.nlpText !== "") {
      writer.uint32(50).string(message.nlpText);
    }
    if (message.confidence !== 0) {
      writer.uint32(21).float(message.confidence);
    }
    for (const v of message.words) {
      WordInfo.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SpeechRecognitionAlternative {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSpeechRecognitionAlternative();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.text = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.slottedText = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.taggedText = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.nlpText = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 21) {
            break;
          }

          message.confidence = reader.float();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.words.push(WordInfo.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SpeechRecognitionAlternative {
    return {
      text: isSet(object.text) ? globalThis.String(object.text) : "",
      slottedText: isSet(object.slottedText) ? globalThis.String(object.slottedText) : "",
      taggedText: isSet(object.taggedText) ? globalThis.String(object.taggedText) : "",
      nlpText: isSet(object.nlpText) ? globalThis.String(object.nlpText) : "",
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
      words: globalThis.Array.isArray(object?.words) ? object.words.map((e: any) => WordInfo.fromJSON(e)) : [],
    };
  },

  toJSON(message: SpeechRecognitionAlternative): unknown {
    const obj: any = {};
    if (message.text !== "") {
      obj.text = message.text;
    }
    if (message.slottedText !== "") {
      obj.slottedText = message.slottedText;
    }
    if (message.taggedText !== "") {
      obj.taggedText = message.taggedText;
    }
    if (message.nlpText !== "") {
      obj.nlpText = message.nlpText;
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    if (message.words?.length) {
      obj.words = message.words.map((e) => WordInfo.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SpeechRecognitionAlternative>, I>>(base?: I): SpeechRecognitionAlternative {
    return SpeechRecognitionAlternative.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SpeechRecognitionAlternative>, I>>(object: I): SpeechRecognitionAlternative {
    const message = createBaseSpeechRecognitionAlternative();
    message.text = object.text ?? "";
    message.slottedText = object.slottedText ?? "";
    message.taggedText = object.taggedText ?? "";
    message.nlpText = object.nlpText ?? "";
    message.confidence = object.confidence ?? 0;
    message.words = object.words?.map((e) => WordInfo.fromPartial(e)) || [];
    return message;
  },
};

function createBaseWordInfo(): WordInfo {
  return { startTime: undefined, endTime: undefined, word: "", confidence: 0, phones: [], slot: "" };
}

export const WordInfo: MessageFns<WordInfo> = {
  encode(message: WordInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Duration.encode(message.startTime, writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Duration.encode(message.endTime, writer.uint32(18).fork()).join();
    }
    if (message.word !== "") {
      writer.uint32(26).string(message.word);
    }
    if (message.confidence !== 0) {
      writer.uint32(37).float(message.confidence);
    }
    for (const v of message.phones) {
      PhoneInfo.encode(v!, writer.uint32(42).fork()).join();
    }
    if (message.slot !== "") {
      writer.uint32(58).string(message.slot);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WordInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWordInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.startTime = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.endTime = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.word = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 37) {
            break;
          }

          message.confidence = reader.float();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.phones.push(PhoneInfo.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.slot = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WordInfo {
    return {
      startTime: isSet(object.startTime) ? Duration.fromJSON(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? Duration.fromJSON(object.endTime) : undefined,
      word: isSet(object.word) ? globalThis.String(object.word) : "",
      confidence: isSet(object.confidence) ? globalThis.Number(object.confidence) : 0,
      phones: globalThis.Array.isArray(object?.phones) ? object.phones.map((e: any) => PhoneInfo.fromJSON(e)) : [],
      slot: isSet(object.slot) ? globalThis.String(object.slot) : "",
    };
  },

  toJSON(message: WordInfo): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = Duration.toJSON(message.startTime);
    }
    if (message.endTime !== undefined) {
      obj.endTime = Duration.toJSON(message.endTime);
    }
    if (message.word !== "") {
      obj.word = message.word;
    }
    if (message.confidence !== 0) {
      obj.confidence = message.confidence;
    }
    if (message.phones?.length) {
      obj.phones = message.phones.map((e) => PhoneInfo.toJSON(e));
    }
    if (message.slot !== "") {
      obj.slot = message.slot;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<WordInfo>, I>>(base?: I): WordInfo {
    return WordInfo.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<WordInfo>, I>>(object: I): WordInfo {
    const message = createBaseWordInfo();
    message.startTime = (object.startTime !== undefined && object.startTime !== null)
      ? Duration.fromPartial(object.startTime)
      : undefined;
    message.endTime = (object.endTime !== undefined && object.endTime !== null)
      ? Duration.fromPartial(object.endTime)
      : undefined;
    message.word = object.word ?? "";
    message.confidence = object.confidence ?? 0;
    message.phones = object.phones?.map((e) => PhoneInfo.fromPartial(e)) || [];
    message.slot = object.slot ?? "";
    return message;
  },
};

function createBasePhoneInfo(): PhoneInfo {
  return { startTime: undefined, endTime: undefined, phone: "" };
}

export const PhoneInfo: MessageFns<PhoneInfo> = {
  encode(message: PhoneInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Duration.encode(message.startTime, writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Duration.encode(message.endTime, writer.uint32(18).fork()).join();
    }
    if (message.phone !== "") {
      writer.uint32(26).string(message.phone);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PhoneInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePhoneInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.startTime = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.endTime = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.phone = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PhoneInfo {
    return {
      startTime: isSet(object.startTime) ? Duration.fromJSON(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? Duration.fromJSON(object.endTime) : undefined,
      phone: isSet(object.phone) ? globalThis.String(object.phone) : "",
    };
  },

  toJSON(message: PhoneInfo): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = Duration.toJSON(message.startTime);
    }
    if (message.endTime !== undefined) {
      obj.endTime = Duration.toJSON(message.endTime);
    }
    if (message.phone !== "") {
      obj.phone = message.phone;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<PhoneInfo>, I>>(base?: I): PhoneInfo {
    return PhoneInfo.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<PhoneInfo>, I>>(object: I): PhoneInfo {
    const message = createBasePhoneInfo();
    message.startTime = (object.startTime !== undefined && object.startTime !== null)
      ? Duration.fromPartial(object.startTime)
      : undefined;
    message.endTime = (object.endTime !== undefined && object.endTime !== null)
      ? Duration.fromPartial(object.endTime)
      : undefined;
    message.phone = object.phone ?? "";
    return message;
  },
};

function createBaseModelsRequest(): ModelsRequest {
  return {};
}

export const ModelsRequest: MessageFns<ModelsRequest> = {
  encode(_: ModelsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModelsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModelsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): ModelsRequest {
    return {};
  },

  toJSON(_: ModelsRequest): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<ModelsRequest>, I>>(base?: I): ModelsRequest {
    return ModelsRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ModelsRequest>, I>>(_: I): ModelsRequest {
    const message = createBaseModelsRequest();
    return message;
  },
};

function createBaseModelsResponse(): ModelsResponse {
  return { model: [] };
}

export const ModelsResponse: MessageFns<ModelsResponse> = {
  encode(message: ModelsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.model) {
      Model.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ModelsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModelsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.model.push(Model.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ModelsResponse {
    return { model: globalThis.Array.isArray(object?.model) ? object.model.map((e: any) => Model.fromJSON(e)) : [] };
  },

  toJSON(message: ModelsResponse): unknown {
    const obj: any = {};
    if (message.model?.length) {
      obj.model = message.model.map((e) => Model.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ModelsResponse>, I>>(base?: I): ModelsResponse {
    return ModelsResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ModelsResponse>, I>>(object: I): ModelsResponse {
    const message = createBaseModelsResponse();
    message.model = object.model?.map((e) => Model.fromPartial(e)) || [];
    return message;
  },
};

function createBaseModel(): Model {
  return {
    id: "",
    alias: [],
    name: "",
    description: "",
    version: "",
    type: 0,
    locale: [],
    grammarType: [],
    nlp: undefined,
    slots: [],
    examples: [],
    endpointing: [],
  };
}

export const Model: MessageFns<Model> = {
  encode(message: Model, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    for (const v of message.alias) {
      writer.uint32(98).string(v!);
    }
    if (message.name !== "") {
      writer.uint32(66).string(message.name);
    }
    if (message.description !== "") {
      writer.uint32(74).string(message.description);
    }
    if (message.version !== "") {
      writer.uint32(82).string(message.version);
    }
    if (message.type !== 0) {
      writer.uint32(16).int32(message.type);
    }
    for (const v of message.locale) {
      writer.uint32(26).string(v!);
    }
    writer.uint32(34).fork();
    for (const v of message.grammarType) {
      writer.int32(v);
    }
    writer.join();
    if (message.nlp !== undefined) {
      NLPSpec.encode(message.nlp, writer.uint32(42).fork()).join();
    }
    for (const v of message.slots) {
      writer.uint32(50).string(v!);
    }
    for (const v of message.examples) {
      writer.uint32(58).string(v!);
    }
    writer.uint32(90).fork();
    for (const v of message.endpointing) {
      writer.int32(v);
    }
    writer.join();
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Model {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseModel();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.alias.push(reader.string());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.version = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.locale.push(reader.string());
          continue;
        }
        case 4: {
          if (tag === 32) {
            message.grammarType.push(reader.int32() as any);

            continue;
          }

          if (tag === 34) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.grammarType.push(reader.int32() as any);
            }

            continue;
          }

          break;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.nlp = NLPSpec.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.slots.push(reader.string());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.examples.push(reader.string());
          continue;
        }
        case 11: {
          if (tag === 88) {
            message.endpointing.push(reader.int32() as any);

            continue;
          }

          if (tag === 90) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.endpointing.push(reader.int32() as any);
            }

            continue;
          }

          break;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Model {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      alias: globalThis.Array.isArray(object?.alias) ? object.alias.map((e: any) => globalThis.String(e)) : [],
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      type: isSet(object.type) ? modelTypeFromJSON(object.type) : 0,
      locale: globalThis.Array.isArray(object?.locale) ? object.locale.map((e: any) => globalThis.String(e)) : [],
      grammarType: globalThis.Array.isArray(object?.grammarType)
        ? object.grammarType.map((e: any) => grammarTypeFromJSON(e))
        : [],
      nlp: isSet(object.nlp) ? NLPSpec.fromJSON(object.nlp) : undefined,
      slots: globalThis.Array.isArray(object?.slots) ? object.slots.map((e: any) => globalThis.String(e)) : [],
      examples: globalThis.Array.isArray(object?.examples) ? object.examples.map((e: any) => globalThis.String(e)) : [],
      endpointing: globalThis.Array.isArray(object?.endpointing)
        ? object.endpointing.map((e: any) => endpointingTypeFromJSON(e))
        : [],
    };
  },

  toJSON(message: Model): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.alias?.length) {
      obj.alias = message.alias;
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.type !== 0) {
      obj.type = modelTypeToJSON(message.type);
    }
    if (message.locale?.length) {
      obj.locale = message.locale;
    }
    if (message.grammarType?.length) {
      obj.grammarType = message.grammarType.map((e) => grammarTypeToJSON(e));
    }
    if (message.nlp !== undefined) {
      obj.nlp = NLPSpec.toJSON(message.nlp);
    }
    if (message.slots?.length) {
      obj.slots = message.slots;
    }
    if (message.examples?.length) {
      obj.examples = message.examples;
    }
    if (message.endpointing?.length) {
      obj.endpointing = message.endpointing.map((e) => endpointingTypeToJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Model>, I>>(base?: I): Model {
    return Model.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Model>, I>>(object: I): Model {
    const message = createBaseModel();
    message.id = object.id ?? "";
    message.alias = object.alias?.map((e) => e) || [];
    message.name = object.name ?? "";
    message.description = object.description ?? "";
    message.version = object.version ?? "";
    message.type = object.type ?? 0;
    message.locale = object.locale?.map((e) => e) || [];
    message.grammarType = object.grammarType?.map((e) => e) || [];
    message.nlp = (object.nlp !== undefined && object.nlp !== null) ? NLPSpec.fromPartial(object.nlp) : undefined;
    message.slots = object.slots?.map((e) => e) || [];
    message.examples = object.examples?.map((e) => e) || [];
    message.endpointing = object.endpointing?.map((e) => e) || [];
    return message;
  },
};

function createBaseNLPFunctionsRequest(): NLPFunctionsRequest {
  return {};
}

export const NLPFunctionsRequest: MessageFns<NLPFunctionsRequest> = {
  encode(_: NLPFunctionsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NLPFunctionsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNLPFunctionsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): NLPFunctionsRequest {
    return {};
  },

  toJSON(_: NLPFunctionsRequest): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<NLPFunctionsRequest>, I>>(base?: I): NLPFunctionsRequest {
    return NLPFunctionsRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NLPFunctionsRequest>, I>>(_: I): NLPFunctionsRequest {
    const message = createBaseNLPFunctionsRequest();
    return message;
  },
};

function createBaseNLPFunctionsResponse(): NLPFunctionsResponse {
  return { server: [] };
}

export const NLPFunctionsResponse: MessageFns<NLPFunctionsResponse> = {
  encode(message: NLPFunctionsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.server) {
      NLPFunctionServer.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NLPFunctionsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNLPFunctionsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.server.push(NLPFunctionServer.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NLPFunctionsResponse {
    return {
      server: globalThis.Array.isArray(object?.server)
        ? object.server.map((e: any) => NLPFunctionServer.fromJSON(e))
        : [],
    };
  },

  toJSON(message: NLPFunctionsResponse): unknown {
    const obj: any = {};
    if (message.server?.length) {
      obj.server = message.server.map((e) => NLPFunctionServer.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NLPFunctionsResponse>, I>>(base?: I): NLPFunctionsResponse {
    return NLPFunctionsResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NLPFunctionsResponse>, I>>(object: I): NLPFunctionsResponse {
    const message = createBaseNLPFunctionsResponse();
    message.server = object.server?.map((e) => NLPFunctionServer.fromPartial(e)) || [];
    return message;
  },
};

function createBaseNLPFunctionServer(): NLPFunctionServer {
  return { serverConfig: "", functions: [] };
}

export const NLPFunctionServer: MessageFns<NLPFunctionServer> = {
  encode(message: NLPFunctionServer, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.serverConfig !== "") {
      writer.uint32(10).string(message.serverConfig);
    }
    for (const v of message.functions) {
      NLPFunction.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NLPFunctionServer {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNLPFunctionServer();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.serverConfig = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.functions.push(NLPFunction.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NLPFunctionServer {
    return {
      serverConfig: isSet(object.serverConfig) ? globalThis.String(object.serverConfig) : "",
      functions: globalThis.Array.isArray(object?.functions)
        ? object.functions.map((e: any) => NLPFunction.fromJSON(e))
        : [],
    };
  },

  toJSON(message: NLPFunctionServer): unknown {
    const obj: any = {};
    if (message.serverConfig !== "") {
      obj.serverConfig = message.serverConfig;
    }
    if (message.functions?.length) {
      obj.functions = message.functions.map((e) => NLPFunction.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NLPFunctionServer>, I>>(base?: I): NLPFunctionServer {
    return NLPFunctionServer.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NLPFunctionServer>, I>>(object: I): NLPFunctionServer {
    const message = createBaseNLPFunctionServer();
    message.serverConfig = object.serverConfig ?? "";
    message.functions = object.functions?.map((e) => NLPFunction.fromPartial(e)) || [];
    return message;
  },
};

function createBaseNLPFunction(): NLPFunction {
  return { id: "", name: "", description: "" };
}

export const NLPFunction: MessageFns<NLPFunction> = {
  encode(message: NLPFunction, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.name !== "") {
      writer.uint32(18).string(message.name);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NLPFunction {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNLPFunction();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NLPFunction {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
    };
  },

  toJSON(message: NLPFunction): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NLPFunction>, I>>(base?: I): NLPFunction {
    return NLPFunction.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NLPFunction>, I>>(object: I): NLPFunction {
    const message = createBaseNLPFunction();
    message.id = object.id ?? "";
    message.name = object.name ?? "";
    message.description = object.description ?? "";
    return message;
  },
};

function createBaseGraph(): Graph {
  return { name: "" };
}

export const Graph: MessageFns<Graph> = {
  encode(message: Graph, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Graph {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGraph();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Graph {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: Graph): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Graph>, I>>(base?: I): Graph {
    return Graph.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Graph>, I>>(object: I): Graph {
    const message = createBaseGraph();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseAccountInfoRequest(): AccountInfoRequest {
  return {};
}

export const AccountInfoRequest: MessageFns<AccountInfoRequest> = {
  encode(_: AccountInfoRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AccountInfoRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAccountInfoRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): AccountInfoRequest {
    return {};
  },

  toJSON(_: AccountInfoRequest): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<AccountInfoRequest>, I>>(base?: I): AccountInfoRequest {
    return AccountInfoRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AccountInfoRequest>, I>>(_: I): AccountInfoRequest {
    const message = createBaseAccountInfoRequest();
    return message;
  },
};

function createBaseAccountInfoResponse(): AccountInfoResponse {
  return {
    token: "",
    displayName: "",
    totalRequests: 0,
    bookedSeconds: 0,
    usedSeconds: 0,
    expirationDate: 0,
    blocked: false,
  };
}

export const AccountInfoResponse: MessageFns<AccountInfoResponse> = {
  encode(message: AccountInfoResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.token !== "") {
      writer.uint32(10).string(message.token);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.totalRequests !== 0) {
      writer.uint32(24).int64(message.totalRequests);
    }
    if (message.bookedSeconds !== 0) {
      writer.uint32(32).int64(message.bookedSeconds);
    }
    if (message.usedSeconds !== 0) {
      writer.uint32(40).int64(message.usedSeconds);
    }
    if (message.expirationDate !== 0) {
      writer.uint32(48).int64(message.expirationDate);
    }
    if (message.blocked !== false) {
      writer.uint32(56).bool(message.blocked);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AccountInfoResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAccountInfoResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.token = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.totalRequests = longToNumber(reader.int64());
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.bookedSeconds = longToNumber(reader.int64());
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.usedSeconds = longToNumber(reader.int64());
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.expirationDate = longToNumber(reader.int64());
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.blocked = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AccountInfoResponse {
    return {
      token: isSet(object.token) ? globalThis.String(object.token) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      totalRequests: isSet(object.totalRequests) ? globalThis.Number(object.totalRequests) : 0,
      bookedSeconds: isSet(object.bookedSeconds) ? globalThis.Number(object.bookedSeconds) : 0,
      usedSeconds: isSet(object.usedSeconds) ? globalThis.Number(object.usedSeconds) : 0,
      expirationDate: isSet(object.expirationDate) ? globalThis.Number(object.expirationDate) : 0,
      blocked: isSet(object.blocked) ? globalThis.Boolean(object.blocked) : false,
    };
  },

  toJSON(message: AccountInfoResponse): unknown {
    const obj: any = {};
    if (message.token !== "") {
      obj.token = message.token;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.totalRequests !== 0) {
      obj.totalRequests = Math.round(message.totalRequests);
    }
    if (message.bookedSeconds !== 0) {
      obj.bookedSeconds = Math.round(message.bookedSeconds);
    }
    if (message.usedSeconds !== 0) {
      obj.usedSeconds = Math.round(message.usedSeconds);
    }
    if (message.expirationDate !== 0) {
      obj.expirationDate = Math.round(message.expirationDate);
    }
    if (message.blocked !== false) {
      obj.blocked = message.blocked;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AccountInfoResponse>, I>>(base?: I): AccountInfoResponse {
    return AccountInfoResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AccountInfoResponse>, I>>(object: I): AccountInfoResponse {
    const message = createBaseAccountInfoResponse();
    message.token = object.token ?? "";
    message.displayName = object.displayName ?? "";
    message.totalRequests = object.totalRequests ?? 0;
    message.bookedSeconds = object.bookedSeconds ?? 0;
    message.usedSeconds = object.usedSeconds ?? 0;
    message.expirationDate = object.expirationDate ?? 0;
    message.blocked = object.blocked ?? false;
    return message;
  },
};

function createBaseNLPProcessRequest(): NLPProcessRequest {
  return { text: "", nlp: undefined };
}

export const NLPProcessRequest: MessageFns<NLPProcessRequest> = {
  encode(message: NLPProcessRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.text !== "") {
      writer.uint32(10).string(message.text);
    }
    if (message.nlp !== undefined) {
      NLPSpec.encode(message.nlp, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NLPProcessRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNLPProcessRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.text = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.nlp = NLPSpec.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NLPProcessRequest {
    return {
      text: isSet(object.text) ? globalThis.String(object.text) : "",
      nlp: isSet(object.nlp) ? NLPSpec.fromJSON(object.nlp) : undefined,
    };
  },

  toJSON(message: NLPProcessRequest): unknown {
    const obj: any = {};
    if (message.text !== "") {
      obj.text = message.text;
    }
    if (message.nlp !== undefined) {
      obj.nlp = NLPSpec.toJSON(message.nlp);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NLPProcessRequest>, I>>(base?: I): NLPProcessRequest {
    return NLPProcessRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NLPProcessRequest>, I>>(object: I): NLPProcessRequest {
    const message = createBaseNLPProcessRequest();
    message.text = object.text ?? "";
    message.nlp = (object.nlp !== undefined && object.nlp !== null) ? NLPSpec.fromPartial(object.nlp) : undefined;
    return message;
  },
};

function createBaseNLPProcessResponse(): NLPProcessResponse {
  return { text: "" };
}

export const NLPProcessResponse: MessageFns<NLPProcessResponse> = {
  encode(message: NLPProcessResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.text !== "") {
      writer.uint32(10).string(message.text);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NLPProcessResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNLPProcessResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.text = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NLPProcessResponse {
    return { text: isSet(object.text) ? globalThis.String(object.text) : "" };
  },

  toJSON(message: NLPProcessResponse): unknown {
    const obj: any = {};
    if (message.text !== "") {
      obj.text = message.text;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NLPProcessResponse>, I>>(base?: I): NLPProcessResponse {
    return NLPProcessResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NLPProcessResponse>, I>>(object: I): NLPProcessResponse {
    const message = createBaseNLPProcessResponse();
    message.text = object.text ?? "";
    return message;
  },
};

export type SttServiceService = typeof SttServiceService;
export const SttServiceService = {
  /** Transcribe a stream of audio. */
  streamingRecognize: {
    path: "/ari.stt.v1.SttService/StreamingRecognize",
    requestStream: true,
    responseStream: true,
    requestSerialize: (value: StreamingRecognitionRequest) =>
      Buffer.from(StreamingRecognitionRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => StreamingRecognitionRequest.decode(value),
    responseSerialize: (value: StreamingRecognitionResponse) =>
      Buffer.from(StreamingRecognitionResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => StreamingRecognitionResponse.decode(value),
  },
  /** List all supported models. */
  models: {
    path: "/ari.stt.v1.SttService/Models",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: ModelsRequest) => Buffer.from(ModelsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => ModelsRequest.decode(value),
    responseSerialize: (value: ModelsResponse) => Buffer.from(ModelsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => ModelsResponse.decode(value),
  },
  /** List all available nlp server configs and corresponding functions. */
  nlpFunctions: {
    path: "/ari.stt.v1.SttService/NLPFunctions",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: NLPFunctionsRequest) => Buffer.from(NLPFunctionsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => NLPFunctionsRequest.decode(value),
    responseSerialize: (value: NLPFunctionsResponse) => Buffer.from(NLPFunctionsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => NLPFunctionsResponse.decode(value),
  },
  accountInfo: {
    path: "/ari.stt.v1.SttService/AccountInfo",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: AccountInfoRequest) => Buffer.from(AccountInfoRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => AccountInfoRequest.decode(value),
    responseSerialize: (value: AccountInfoResponse) => Buffer.from(AccountInfoResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => AccountInfoResponse.decode(value),
  },
  /** Processes the given text with the given nlp pipeline. */
  nlpProcess: {
    path: "/ari.stt.v1.SttService/NLPProcess",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: NLPProcessRequest) => Buffer.from(NLPProcessRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => NLPProcessRequest.decode(value),
    responseSerialize: (value: NLPProcessResponse) => Buffer.from(NLPProcessResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => NLPProcessResponse.decode(value),
  },
} as const;

export interface SttServiceServer extends UntypedServiceImplementation {
  /** Transcribe a stream of audio. */
  streamingRecognize: handleBidiStreamingCall<StreamingRecognitionRequest, StreamingRecognitionResponse>;
  /** List all supported models. */
  models: handleUnaryCall<ModelsRequest, ModelsResponse>;
  /** List all available nlp server configs and corresponding functions. */
  nlpFunctions: handleUnaryCall<NLPFunctionsRequest, NLPFunctionsResponse>;
  accountInfo: handleUnaryCall<AccountInfoRequest, AccountInfoResponse>;
  /** Processes the given text with the given nlp pipeline. */
  nlpProcess: handleUnaryCall<NLPProcessRequest, NLPProcessResponse>;
}

export interface SttServiceClient extends Client {
  /** Transcribe a stream of audio. */
  streamingRecognize(): ClientDuplexStream<StreamingRecognitionRequest, StreamingRecognitionResponse>;
  streamingRecognize(
    options: Partial<CallOptions>,
  ): ClientDuplexStream<StreamingRecognitionRequest, StreamingRecognitionResponse>;
  streamingRecognize(
    metadata: Metadata,
    options?: Partial<CallOptions>,
  ): ClientDuplexStream<StreamingRecognitionRequest, StreamingRecognitionResponse>;
  /** List all supported models. */
  models(
    request: ModelsRequest,
    callback: (error: ServiceError | null, response: ModelsResponse) => void,
  ): ClientUnaryCall;
  models(
    request: ModelsRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: ModelsResponse) => void,
  ): ClientUnaryCall;
  models(
    request: ModelsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: ModelsResponse) => void,
  ): ClientUnaryCall;
  /** List all available nlp server configs and corresponding functions. */
  nlpFunctions(
    request: NLPFunctionsRequest,
    callback: (error: ServiceError | null, response: NLPFunctionsResponse) => void,
  ): ClientUnaryCall;
  nlpFunctions(
    request: NLPFunctionsRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: NLPFunctionsResponse) => void,
  ): ClientUnaryCall;
  nlpFunctions(
    request: NLPFunctionsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: NLPFunctionsResponse) => void,
  ): ClientUnaryCall;
  accountInfo(
    request: AccountInfoRequest,
    callback: (error: ServiceError | null, response: AccountInfoResponse) => void,
  ): ClientUnaryCall;
  accountInfo(
    request: AccountInfoRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: AccountInfoResponse) => void,
  ): ClientUnaryCall;
  accountInfo(
    request: AccountInfoRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: AccountInfoResponse) => void,
  ): ClientUnaryCall;
  /** Processes the given text with the given nlp pipeline. */
  nlpProcess(
    request: NLPProcessRequest,
    callback: (error: ServiceError | null, response: NLPProcessResponse) => void,
  ): ClientUnaryCall;
  nlpProcess(
    request: NLPProcessRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: NLPProcessResponse) => void,
  ): ClientUnaryCall;
  nlpProcess(
    request: NLPProcessRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: NLPProcessResponse) => void,
  ): ClientUnaryCall;
}

export const SttServiceClient = makeGenericClientConstructor(SttServiceService, "ari.stt.v1.SttService") as unknown as {
  new (address: string, credentials: ChannelCredentials, options?: Partial<ClientOptions>): SttServiceClient;
  service: typeof SttServiceService;
  serviceName: string;
};

function bytesFromBase64(b64: string): Uint8Array {
  if ((globalThis as any).Buffer) {
    return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
  } else {
    const bin = globalThis.atob(b64);
    const arr = new Uint8Array(bin.length);
    for (let i = 0; i < bin.length; ++i) {
      arr[i] = bin.charCodeAt(i);
    }
    return arr;
  }
}

function base64FromBytes(arr: Uint8Array): string {
  if ((globalThis as any).Buffer) {
    return globalThis.Buffer.from(arr).toString("base64");
  } else {
    const bin: string[] = [];
    arr.forEach((byte) => {
      bin.push(globalThis.String.fromCharCode(byte));
    });
    return globalThis.btoa(bin.join(""));
  }
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P>>]: never };

function longToNumber(int64: { toString(): string }): number {
  const num = globalThis.Number(int64.toString());
  if (num > globalThis.Number.MAX_SAFE_INTEGER) {
    throw new globalThis.Error("Value is larger than Number.MAX_SAFE_INTEGER");
  }
  if (num < globalThis.Number.MIN_SAFE_INTEGER) {
    throw new globalThis.Error("Value is smaller than Number.MIN_SAFE_INTEGER");
  }
  return num;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
